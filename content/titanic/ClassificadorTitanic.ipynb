{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Vamos explorar aqui como criar um classificador básico utilizando o *dataset* [Titanic](https://www.kaggle.com/c/titanic) do Kaggle. Esse é um problema de classificação simples, binária, onde devemos prever se um passageiro do navio irá ou não sobreviver, dado um conjunto de características (*features*) que ele possui (idade, sexo, porto de embarque etc.).\n",
    "\n",
    "Nessa implementação vamos utilizar a biblioteca scikit-learn, com o classificador [RandomForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "A ideia é mostrar, numa abordagem top-down, como é rápida a criação de um classificador que prevê um resultado de um problema, sem muito conhecimento prévio, e já obtendo resultados minimamente aceitáveis.\n",
    "\n",
    "Durante a solução do problemas, serão apresentados conceitos relacionados a implementação de um classificador em *Machine Learning*:\n",
    "\n",
    "- exploração dos dados;\n",
    "- pré-processamento de dados\n",
    "- importância da separação dos *sets* de treino e validação;\n",
    "- *overfitting*;\n",
    "- dentre outros.\n",
    "\n",
    "Vamos lá!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas Utilizadas\n",
    "\n",
    "O código foi implementado em Python 3, utilizando as seguintes bibliotecas:\n",
    "\n",
    "- pandas\n",
    "- scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "# os dados estão na pasta data\n",
    "\n",
    "PATH = \"data/\"\n",
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciando o pré-processamento\n",
    "\n",
    "Vamos ler os arquivos de treino e de teste. Ambos são arquivos *.csv*; geralmente, o Kaggle disponibiliza em seus problemas os arquivos de treino e teste separados, de forma que o modelo seja treinado e melhorado com os dados do arquivo de treino e validado junto aos dados do arquivo de teste.\n",
    "\n",
    "Vamos utilizar um [DataFrame](http://pandas.pydata.org/pandas-docs/version/0.19/generated/pandas.DataFrame.html) do [pandas](https://pandas.pydata.org/). No código abaixo, a saída do arquivo é direcionada para dois *DataFrames* distintos: df_train e df_test.\n",
    "\n",
    "**Nota**: Um *DataFrame* é uma estrutura de dados bidimensional, com linhas e colunas. Para efeitos de comparação, pense em *DataFrame* como uma tabela de um banco de dados relacional ou uma planilha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(f'{PATH}train.csv')\n",
    "df_test = pd.read_csv(f'{PATH}test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar o pré-processamento, vamos juntar os 2 *DataFrames* em um só. Isso costuma ser uma **boa prática**, pois, temos as seguintes vantagens:\n",
    "\n",
    "- remoção de colunas: às vezes, optamos por remover uma coluna por algum motivo; ao retirar uma coluna dos dados de treino, precisamos também removê-la dos dados de teste (ambos os conjunto de dados precisam ter o mesmo conjunto de colunas - *features*, sob pena de termos um erro ao tentar construir o modelo);\n",
    "- remoção/tratamento uniforme de dados nulos;\n",
    "- consistência na criação de variáveis categóricas (se todas as categorias não estiverem presentes nos dois conjuntos de dados, elas podem ser codificadas de forma diferente se isso for feito em duas operações em separado) - isso vai ficar mais claro adiante;\n",
    "\n",
    "Portanto, juntar os 2 conjunto de dados uniformiza e padroniza o tratamento, de forma que o modelo criado lide de forma consistente nos dois casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 418, 1309)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = df_train.append(df_test, sort = False)\n",
    "len(df_train), len(df_test), len(df_raw) # listando o tamanho de cada um dos datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos listar as colunas (*features*) presente em nosso *data set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visão geral dos dos dados\n",
    "\n",
    "Antes de começarmos a trabalhar com os dados, é bom termos uma visão geral dos dados.\n",
    "\n",
    "Vamos dar uma olhada geral nos dados que temos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Salomon, Mr. Abraham L</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111163</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Davies, Master. John Morgan Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 33112</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Nancarrow, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A./5. 3338</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Molson, Mr. Harry Markland</td>\n",
       "      <td>male</td>\n",
       "      <td>55.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113787</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>C30</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Silverthorne, Mr. Spencer Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17475</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>E24</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Caldwell, Master. Alden Gates</td>\n",
       "      <td>male</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>248738</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Salkjelsvik, Miss. Anna Kristine</td>\n",
       "      <td>female</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343120</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Keefe, Mr. Arthur</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323592</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330972</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Lyntakoff, Mr. Stanko</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349235</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                              Name     Sex  \\\n",
       "191         1083       NaN       1            Salomon, Mr. Abraham L    male   \n",
       "549          550       1.0       2    Davies, Master. John Morgan Jr    male   \n",
       "99           991       NaN       3      Nancarrow, Mr. William Henry    male   \n",
       "492          493       0.0       1        Molson, Mr. Harry Markland    male   \n",
       "701          702       1.0       1  Silverthorne, Mr. Spencer Victor    male   \n",
       "78            79       1.0       2     Caldwell, Master. Alden Gates    male   \n",
       "106          107       1.0       3  Salkjelsvik, Miss. Anna Kristine  female   \n",
       "470          471       0.0       3                 Keefe, Mr. Arthur    male   \n",
       "6            898       NaN       3              Connolly, Miss. Kate  female   \n",
       "265         1157       NaN       3             Lyntakoff, Mr. Stanko    male   \n",
       "\n",
       "       Age  SibSp  Parch      Ticket     Fare Cabin Embarked  \n",
       "191    NaN      0      0      111163  26.0000   NaN        S  \n",
       "549   8.00      1      1  C.A. 33112  36.7500   NaN        S  \n",
       "99   33.00      0      0  A./5. 3338   8.0500   NaN        S  \n",
       "492  55.00      0      0      113787  30.5000   C30        S  \n",
       "701  35.00      0      0    PC 17475  26.2875   E24        S  \n",
       "78    0.83      0      2      248738  29.0000   NaN        S  \n",
       "106  21.00      0      0      343120   7.6500   NaN        S  \n",
       "470    NaN      0      0      323592   7.2500   NaN        S  \n",
       "6    30.00      0      0      330972   7.6292   NaN        Q  \n",
       "265    NaN      0      0      349235   7.8958   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A listagem acima é uma exibição **aleatória** (*sample(10)*) de 10 linhas; é interessante porque nos permite ter uma visão geral dos tipos dos dados que temos (numéricos, categóricos, textuais), presença de valores nulos etc.\n",
    "\n",
    "Podemos visualizar, também, um **sumário estatístico dos dados**. Para isso, usamos o método *describe()* do *DataFrame*. Esse método nos retorna um outro DataFrame com diversas estatísticas: número de entradas, média, desvio-padrão, valor mínimo, valor máximo e percentis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>982.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived       Pclass          Age        SibSp  \\\n",
       "count  1309.000000  891.000000  1309.000000  1046.000000  1309.000000   \n",
       "mean    655.000000    0.383838     2.294882    29.881138     0.498854   \n",
       "std     378.020061    0.486592     0.837836    14.413493     1.041658   \n",
       "min       1.000000    0.000000     1.000000     0.170000     0.000000   \n",
       "25%     328.000000    0.000000     2.000000    21.000000     0.000000   \n",
       "50%     655.000000    0.000000     3.000000    28.000000     0.000000   \n",
       "75%     982.000000    1.000000     3.000000    39.000000     1.000000   \n",
       "max    1309.000000    1.000000     3.000000    80.000000     8.000000   \n",
       "\n",
       "             Parch         Fare  \n",
       "count  1309.000000  1308.000000  \n",
       "mean      0.385027    33.295479  \n",
       "std       0.865560    51.758668  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     7.895800  \n",
       "50%       0.000000    14.454200  \n",
       "75%       0.000000    31.275000  \n",
       "max       9.000000   512.329200  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: colunas com valores não numéricos são excluídas dessa visualização (veja que a coluna *Name* não aparece, por exemplo).\n",
    "\n",
    "Vamos listar as colunas com **valores nulos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin          0.774637\n",
       "Survived       0.319328\n",
       "Age            0.200917\n",
       "Embarked       0.001528\n",
       "Fare           0.000764\n",
       "Ticket         0.000000\n",
       "Parch          0.000000\n",
       "SibSp          0.000000\n",
       "Sex            0.000000\n",
       "Name           0.000000\n",
       "Pclass         0.000000\n",
       "PassengerId    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_raw.isnull().sum()/len(df_raw)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das saídas anteriores, podemos tirar algumas conclusões:\n",
    "\n",
    "- As colunas *Age*, *Cabin*, *Embarked* possuem valores nulos (*Survived* é a nossa variável dependente, isto é, o valor que queremos prever; esses valores nulos referem-se às entradas do arquivo de teste);\n",
    "- A coluna *Sex*, *Ticket* e *Embarked* devem ser categorizadas - os algoritmos de *Machine Learning* precisam de entradas do tipo numérico - não sabem lidar com texto;\n",
    "- As colunas *Name*  e *PassengerId*, em princípio, não fazem sentido. Provavelmente nossa variável dependente, *Survived*, não se relaciona com elas. Logo, podemos removê-las."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando os nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria das bibliotecas de *Machine Learning*, incluindo a scikit-learn, disparam erros ao usar dados com valores nulos. Por isso precisamos tratar esses valores. Temos algumas alternativas:\n",
    "\n",
    "- **remover as linhas** com valores nulos (essa não costuma ser uma boa ideia, pois, estamos jogando fora linhas que possuem outras informações por causa de valores nulos em determinadas colunas);\n",
    "- **remover as colunas** que possuem valores nulos (sob pena de perda de informação, caso elas sejam úteis);\n",
    "- ***Imputation***: preencher os valores nulos com algum valor; por exemplo, podemos substituir os nulos presentes em uma coluna pela média, mediana ou moda dos valores da coluna; esse procedimento nos dá um melhor resultado do que a simples remoção da coluna;\n",
    "\n",
    "Vamos usar as duas últimas alternativas acima. \n",
    "\n",
    "**Nota**: dado ao alto índice de valores nulos (77%), vamos optar por remover a coluna *Cabin*;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df_raw.copy()\n",
    "df_copy.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma boa prática, antes de fazer os tratamentos necessários nos dados, é criar uma cópia dos dados originais, de forma que estes fiquem intactos. Foi isso que fizemos ao criar a variável *df_copy*.\n",
    "\n",
    "Para as colunas *Age* e *Fare*, vamos colocar no lugar dos valores nulos a média das idades presentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_not_null = df_copy[df_copy['Age'].isnull() == False]['Age']\n",
    "fare_not_null = df_copy[df_copy['Fare'].isnull() == False]['Fare']\n",
    "mean_age = age_not_null.mean()\n",
    "mean_fare = fare_not_null.mean()\n",
    "df_copy.fillna(value = {'Age':mean_age, 'Fare' : mean_fare}, inplace=True) # substituímos os nulos pela média"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a coluna *Embarked*, do tipo categórica, podemos usar a moda.\n",
    "\n",
    "Vamos visualizar os dados presentes nessa coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd982028290>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy['Embarked'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor mais comun, a moda, é o valor 'S'. Vamos substituir os valores nulos por 'S'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.fillna(value={'Embarked': 'S'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver agora os valores nulos que temos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       0.319328\n",
       "Embarked       0.000000\n",
       "Fare           0.000000\n",
       "Ticket         0.000000\n",
       "Parch          0.000000\n",
       "SibSp          0.000000\n",
       "Age            0.000000\n",
       "Sex            0.000000\n",
       "Name           0.000000\n",
       "Pclass         0.000000\n",
       "PassengerId    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_copy.isnull().sum()/len(df_copy)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto. Tratamos todos os nulos. Podemos prosseguir com o pré-processamento de dados.\n",
    "\n",
    "**Nota**: lembre-se que a coluna *Survived* tem valores nulos provenientes dos dados do arquivo de teste - é o que vamos prever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lidando com variáveis categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis categóricas são aquelas cujos valores são limitados a um conjunto de valores. Um exemplo de variável categórica em nosso conjunto de dados é *Embarked*, que representa o porto de embarque; os seus valores são 'S', 'C' e 'Q'.\n",
    "\n",
    "Assim como no caso dos valores nulos, passar variáveis categóricas para modelos de *Machine Learning* também resultam em erros. Por isso precisamos tratar esses valores.\n",
    "\n",
    "A forma mais popular de tratamento de variáveis categóricas é o **One-Hot Encoding**.\n",
    "\n",
    "**One-Hot Encoding** cria novas colunas, binárias, indicando a presença ou ausência de cada um dos valores categóricos no conjunto de dados original. É uma boa técnica quando o conjunto de valores categóricos não é muito grande - caso contrário, vamos ter uma explosão de colunas.\n",
    "\n",
    "Primeiramente, vamos visualizar os tipos de dados de cada uma das nossas colunas (*features*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived       float64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis do tipo **object** indicam que elas possuem texto. Essas, em geral, são colunas que devem passar pelo processo de *encoding*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 1307, 'Sex': 2, 'Ticket': 929, 'Embarked': 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos verificar a quantidade de valores únicos em cada uma dessas colunas object.\n",
    "unique_values = {}\n",
    "for col in df_copy.columns:\n",
    "    if df_copy[col].dtype == 'object':\n",
    "        unique_values[col] = len(df_copy[col].unique())\n",
    "        \n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se fizemos *one-hot encoding* diretamente, as colunas *Name* e *Ticket* vão gerar diversas colunas binárias. Logo, não é uma boa ideia usar o encoding nelas.\n",
    "\n",
    "Primeiramente, vamos ignorar a coluna *Name*. Vamos fazer isso porque o hot-encoding dela geraria uma explosão de colunas; e, também, porque conforme dissemos anteriomente, acreditamos que ela não deve estar relacionada com a variável alvo, não devendo ter, portanto, importância para o modelo (o nome da pessoa não deve influenciar se ela sobrevive ou não).\n",
    "\n",
    "Depois, vamos categorizar as variáveis *Ticket* e *Sex*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.drop('Name', axis=1, inplace=True)\n",
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transformamos texto em categoria\n",
    "df_copy['Ticket'] = df_copy['Ticket'].astype('category')\n",
    "df_copy['Sex'] = df_copy['Sex'].astype('category')\n",
    "# Substitui os valores pelos códigos de cada categoria\n",
    "df_copy['Ticket'] = df_copy['Ticket'].cat.codes\n",
    "df_copy['Sex'] = df_copy['Sex'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>305</td>\n",
       "      <td>32.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>883</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>286</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>381</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>611</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>286</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>768</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex        Age  SibSp  Parch  Ticket  \\\n",
       "416          417       1.0       2    0  34.000000      1      1     305   \n",
       "568          569       0.0       3    1  29.881138      0      0     281   \n",
       "47           939       NaN       3    1  29.881138      0      0     640   \n",
       "281         1173       NaN       3    1   0.750000      1      1     883   \n",
       "362          363       0.0       3    0  45.000000      0      1     286   \n",
       "358          359       1.0       3    0  29.881138      0      0     381   \n",
       "214          215       0.0       3    1  29.881138      1      0     611   \n",
       "702          703       0.0       3    0  18.000000      0      1     286   \n",
       "190          191       1.0       2    0  32.000000      0      0     156   \n",
       "58            59       1.0       2    0   5.000000      1      2     768   \n",
       "\n",
       "        Fare Embarked  \n",
       "416  32.5000        S  \n",
       "568   7.2292        C  \n",
       "47    7.7500        Q  \n",
       "281  13.7750        S  \n",
       "362  14.4542        C  \n",
       "358   7.8792        Q  \n",
       "214   7.7500        Q  \n",
       "702  14.4542        C  \n",
       "190  13.0000        S  \n",
       "58   27.7500        S  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, as variáveis *Ticket* e *Sex* tiveram seus valores substituídos pelos códigos numéricos correspondentes.\n",
    "\n",
    "Agora, finalmente, vamos aplicar o one-hot encoding no DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = pd.get_dummies(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função *get_dummies* do pandas permite fazer *one-hot encoding*, convertendo variáveis categóricas em variáveis indicadores (*dummy*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>89.1042</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>805</td>\n",
       "      <td>153.4625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>581</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>765</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>696</td>\n",
       "      <td>8.9625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex        Age  SibSp  Parch  Ticket  \\\n",
       "849          850       1.0       1    0  29.881138      1      0     108   \n",
       "257         1149       NaN       3    1  28.000000      0      0     586   \n",
       "551          552       0.0       2    1  27.000000      0      0     196   \n",
       "237         1129       NaN       3    1  20.000000      0      0     274   \n",
       "609          610       1.0       1    0  40.000000      0      0     805   \n",
       "706          707       1.0       2    0  45.000000      0      0     140   \n",
       "580          581       1.0       2    0  25.000000      1      1     175   \n",
       "204         1096       NaN       2    1  25.000000      0      0     765   \n",
       "244          245       0.0       3    1  30.000000      0      0     289   \n",
       "169         1061       NaN       3    0  22.000000      0      0     696   \n",
       "\n",
       "         Fare  Embarked_C  Embarked_Q  Embarked_S  \n",
       "849   89.1042           1           0           0  \n",
       "257    8.0500           0           0           1  \n",
       "551   26.0000           0           0           1  \n",
       "237    7.2250           1           0           0  \n",
       "609  153.4625           0           0           1  \n",
       "706   13.5000           0           0           1  \n",
       "580   30.0000           0           0           1  \n",
       "204   10.5000           0           0           1  \n",
       "244    7.2250           1           0           0  \n",
       "169    8.9625           0           0           1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare essa saída com a saída do penúltimo *sample()*.\n",
    "\n",
    "Observe, nessa última saída, que foram criadas variáveis adicionais derivadas de *Embarked*:  \n",
    "\n",
    "- *Embarked_C*: indicando que o valor original era 'C';\n",
    "- *Embarked_Q*: indicando que o valor original era 'Q';\n",
    "- *Embarked_S*: indicando que o valor original era 'S';\n",
    "\n",
    "Em cada linha, somente uma dessas variáveis terá seu valor igual a 1, com as outras tendo o valor 0.\n",
    "\n",
    "Agora, com todas as variáveis tendo valores numéricos, podemos partir para o treino do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando um modelo\n",
    "\n",
    "Finalmente podemos treinar o modelo. Vamos, primeiramente, separar novamente os data sets de treino e teste, conforme os arquivos originalmente nos fornecidos pelo Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_copy[0:891] # o tamanho original do arquivo de treino é 891\n",
    "df_test = df_copy[891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de agora, vamos utilizar o conjunto de treino para fazer o treino do nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n"
     ]
    }
   ],
   "source": [
    "cols_to_remove = ['PassengerId', 'Survived']\n",
    "\n",
    "features = [c for c in df_train.columns if c not in cols_to_remove]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No trecho anterior removemos as variáveis *PassengerId* (pelo fato de acreditarmos que ela não se relaciona com a nossa variável alvo - é apenas um sequencial numérico) e a variável alvo *Survived*. O objetivo é selecionar as *features* que vamos utilizar para treinar nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# usando n_estimators = 100, para suprimir warning\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(df_train[features], df_train['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No trecho anterior, criamos um classificador do tipo RandomForest e em seguida chamamos o seu método *fit*, para fazer o **treino** do modelo - a construção das árvores, neste caso.\n",
    "\n",
    "COLOCAR LINK RANDOM FOREST\n",
    "\n",
    "O primeiro argumento de *fit* é a entrada para o treino (X); o segundo argumento é a variável alvo (y).\n",
    "\n",
    "Agora vamos fazer a **previsão** do resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(df_train[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função *predict()* nos retorna os valores que queremos prever, neste caso, o valor de *Survived*.\n",
    "\n",
    "Esse é o padrão para treino de modelos utilizando scikit-learn: chamar *fit* para fazer o ajuste e depois *predict* para fazer a previsão.\n",
    "\n",
    "FIGURA FIT-PREDICT\n",
    "\n",
    "Vamos ver a acurácia das nossas previsões no dataset de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988776655443322"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(df_train['Survived'], train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos como métrica a acurácia - essa é a métrica recomendada pelo Kaggle para esse problema. Fizemos uso do *accuracy_score* do scikit-learn; o seu primeiro argumento são os valores reais; o segundo argumento são os valores previstos, obtidos como saída do classificador.\n",
    "\n",
    "Nesse caso, o modelo está conseguindo acertar 99% das previsões.\n",
    "\n",
    "O que fizemos até agora nos garante que o nosso modelo tem um ótimo desempenho nos dados do conjunto de treino - quase 100%. Esse são os dados conhecidos. \n",
    "\n",
    "No entanto, precisamos garantir que o modelo também se comporte bem para dados que ele ainda não conhece; em outras palavras, queremos um modelo/classificador que generalize bem para novos dados que lhe sejam apresentados - evitar o ***overfitting***.\n",
    "\n",
    "Para avaliar quão bom é o desempenho do modelo treinado em dados desconhecidos, vamos separar o conjunto de dados de treino em 2 outros conjuntos separados: treino e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split: Criando os conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 10), (179, 10), (712,), (179,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[features], df_train['Survived'], test_size = 0.2, random_state = 42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fizemos uso da função *train_test_split* do scikit-learn para separar, aleatoriamente, o dataset de treino df_train em outros dois datasets independentes: X_train e X_test (80% dos dados vão ser usados para o treino; 20% para fazer o teste/validação do modelo).\n",
    "\n",
    "Agora, vamos treinar o modelo utilizando o X_train e avaliá-lo utilizando o X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9985955056179775, 0.8044692737430168)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_train, model.predict(X_train)), accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, o desempenho no set de treino é bem maior do que no set de teste: 99% vs 80% - embora precisão de 80% seja um resultado razoável. O que está ocorrendo aqui é o ***overfitting***.\n",
    "\n",
    "O ***overfitting*** ocorre quando o modelo captura bem as características presentes no set de treinamento, mas falha ao generalizar seu comportamento para dados que ele desconhece - fazendo uma analogia, é como se ele decorasse as características existentes, em vez de aprendê-las.\n",
    "\n",
    "Há diversas formas de tratar o overfitting, como melhora de hiperparâmetros, melhor tratamento de dados, etc. Não vamos entrar nesse tópico, para não fugir do nosso objetivo, que é a criação de um classificador simples e rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando se o classificador criado é bom\n",
    "\n",
    "Vimos que o classificador tem uma acurácia de 80% no dataset de teste. 80%, para a maioria dos problemas, parece ser um bom resultado. Mas quão bom é esse valor?\n",
    "\n",
    "Vamos comparar o nosso classificador com um classificador que *dummy*, isto é, um classificador que sempre prevê o mesmo valor (por exemplo, ele sempre \"chuta\" que o passageiro vai morrer). Esperamos que o nosso classificador seja melhor que esse, caso contrário, não faz sentido utilizá-lo.\n",
    "\n",
    "Vamos dar uma olhada nos nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd97ed65650>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['Survived'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer um classificador que, independentemente dos dados, sempre chuta que o passageiro vai morrer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6235955056179775, 0.5865921787709497)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# cria um classificador que faz previsões baseados na classe mais frequente\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_train, dummy.predict(X_train)), accuracy_score(y_test, dummy.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme podemos ver, a acurácia do classificador que sempre prevê o mesmo valor, é de 58.6% nos dados de teste. Logo, o nosso classificador baseado em RandomForest está bem melhor que esse.\n",
    "\n",
    "Vamos fazer a análise final, que seria a submissão dos resultados para o Kaggle, baseado no arquivo com os dados de testes que nos foi fornecido (test.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado junto ao arquivo de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "output_predictions = model.predict(df_test[features])\n",
    "print(output_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'PassengerId': df_test['PassengerId'], 'Survived': output_predictions})\n",
    "my_submission.Survived = my_submission.Survived.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escrevendo o arquivo de saída\n",
    "my_submission.to_csv(f'{PATH}submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto. O arquivo está pronto para ser enviado para o Kaggle.\n",
    "\n",
    "**Nota**: A título de curiosidade, o score desse classificador no Kaggle foi 0.7751. Ou seja, acurácia de 77.5%. Cabe lembrar que não fizemos nenhuma otimização no nosso classificador. Apenas tratamos os dados e fizemos a classificação. Então é um resultado bastante aceitável para uma primeira experiência."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
