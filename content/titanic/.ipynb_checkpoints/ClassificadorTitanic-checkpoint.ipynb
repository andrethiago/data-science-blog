{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Vamos explorar aqui como criar um classificador básico utilizando o *dataset* [Titanic](https://www.kaggle.com/c/titanic) do Kaggle. Esse é um problema de classificação simples, binária, onde devemos prever se um passageiro do navio irá ou não sobreviver, dado um conjunto de características (*features*) que ele possui (idade, sexo, porto de embarque etc.).\n",
    "\n",
    "Nessa implementação vamos utilizar a biblioteca scikit-learn, com o classificador [RandomForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "A ideia é mostrar, numa abordagem top-down, como é rápida a criação de um classificador que prevê um resultado de um problema, sem muito conhecimento prévio, e já obtendo resultados minimamente aceitáveis.\n",
    "\n",
    "Durante a solução do problemas, serão apresentados conceitos relacionados a implementação de um classificador em *Machine Learning*:\n",
    "\n",
    "- exploração dos dados;\n",
    "- pré-processamento de dados\n",
    "- importância da separação dos *sets* de treino e validação;\n",
    "- *overfitting*;\n",
    "- dentre outros.\n",
    "\n",
    "Vamos lá!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas Utilizadas\n",
    "\n",
    "O código foi implementado em Python 3, utilizando as seguintes bibliotecas:\n",
    "\n",
    "- pandas\n",
    "- scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "# os dados estão na pasta data\n",
    "\n",
    "PATH = \"data/\"\n",
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciando o pré-processamento\n",
    "\n",
    "Vamos ler os arquivos de treino e de teste. Ambos são arquivos *.csv*; geralmente, o Kaggle disponibiliza em seus problemas os arquivos de treino e teste separados, de forma que o modelo seja treinado e melhorado com os dados do arquivo de treino e validado junto aos dados do arquivo de teste.\n",
    "\n",
    "Vamos utilizar um [DataFrame](http://pandas.pydata.org/pandas-docs/version/0.19/generated/pandas.DataFrame.html) do [pandas](https://pandas.pydata.org/). No código abaixo, a saída do arquivo é direcionada para dois *DataFrames* distintos: df_train e df_test.\n",
    "\n",
    "**Nota**: Um *DataFrame* é uma estrutura de dados bidimensional, com linhas e colunas. Para efeitos de comparação, pense em *DataFrame* como uma tabela de um banco de dados relacional ou uma planilha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(f'{PATH}train.csv')\n",
    "df_test = pd.read_csv(f'{PATH}test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar o pré-processamento, vamos juntar os 2 *DataFrames* em um só. Isso costuma ser uma **boa prática**, pois, temos as seguintes vantagens:\n",
    "\n",
    "- remoção de colunas: às vezes, optamos por remover uma coluna por algum motivo; ao retirar uma coluna dos dados de treino, precisamos também removê-la dos dados de teste (ambos os sets precisam ter o mesmo conjunto de *features*);\n",
    "- remoção/tratamento uniforme de dados nulos;\n",
    "- consistência na criação de variáveis categóricas (se todas as categorias não estiverem presentes nos dois *sets*, elas podem ser codificadas de forma diferente se isso for feito em duas operações em separado) - isso vai ficar mais claro adiante;\n",
    "\n",
    "Portanto, juntar os 2 sets de dados uniformiza e padroniza o tratamento de dados, de forma que o modelo criado lide de forma consistente nos dois casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 418, 1309)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = df_train.append(df_test, sort = False)\n",
    "len(df_train), len(df_test), len(df_raw) # listando o tamanho de cada um dos datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos listar as colunas (*features*) presente em nosso *data set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visão geral dos dos dados\n",
    "\n",
    "Vamos dar uma olhada geral nos dados que temos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Newell, Mr. Arthur Webster</td>\n",
       "      <td>male</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35273</td>\n",
       "      <td>113.2750</td>\n",
       "      <td>D48</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Stahelin-Maeglin, Dr. Max</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13214</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>B50</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Davidson, Mr. Thornton</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F.C. 12750</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>B71</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Leary, Miss. Hanora \"Norah\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330919</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Dodge, Master. Washington</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33638</td>\n",
       "      <td>81.8583</td>\n",
       "      <td>A34</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hale, Mr. Reginald</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250653</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Foley, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365235</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Slemen, Mr. Richard James</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28206</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hanna, Mr. Mansour</td>\n",
       "      <td>male</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2693</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                           Name     Sex  \\\n",
       "659          660       0.0       1     Newell, Mr. Arthur Webster    male   \n",
       "632          633       1.0       1      Stahelin-Maeglin, Dr. Max    male   \n",
       "671          672       0.0       1         Davidson, Mr. Thornton    male   \n",
       "653          654       1.0       3  O'Leary, Miss. Hanora \"Norah\"  female   \n",
       "445          446       1.0       1      Dodge, Master. Washington    male   \n",
       "806          807       0.0       1         Andrews, Mr. Thomas Jr    male   \n",
       "178          179       0.0       2             Hale, Mr. Reginald    male   \n",
       "102          994       NaN       3             Foley, Mr. William    male   \n",
       "812          813       0.0       2      Slemen, Mr. Richard James    male   \n",
       "296          297       0.0       3             Hanna, Mr. Mansour    male   \n",
       "\n",
       "      Age  SibSp  Parch      Ticket      Fare Cabin Embarked  \n",
       "659  58.0      0      2       35273  113.2750   D48        C  \n",
       "632  32.0      0      0       13214   30.5000   B50        C  \n",
       "671  31.0      1      0  F.C. 12750   52.0000   B71        S  \n",
       "653   NaN      0      0      330919    7.8292   NaN        Q  \n",
       "445   4.0      0      2       33638   81.8583   A34        S  \n",
       "806  39.0      0      0      112050    0.0000   A36        S  \n",
       "178  30.0      0      0      250653   13.0000   NaN        S  \n",
       "102   NaN      0      0      365235    7.7500   NaN        Q  \n",
       "812  35.0      0      0       28206   10.5000   NaN        S  \n",
       "296  23.5      0      0        2693    7.2292   NaN        C  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A listagem acima é uma exibição aleatória de 10 linhas (*sample(10)*); é interessante porque nos permite ter uma visão geral dos tipos dos dados que temos (numéricos, categóricos, textuais), presença de valores nulos etc.\n",
    "\n",
    "Podemos visualizar, também, um **sumário estatístico dos dados**. Para isso, usamos o método *describe()* do *DataFrame*. Esse método nos retorna um outro DataFrame com diversas estatísticas: número de entradas, média, desvio-padrão, valor mínimo, valor máximo e percentis.\n",
    "\n",
    "Isso é uma forma de ter uma visão geral dos dados que temos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>982.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived       Pclass          Age        SibSp  \\\n",
       "count  1309.000000  891.000000  1309.000000  1046.000000  1309.000000   \n",
       "mean    655.000000    0.383838     2.294882    29.881138     0.498854   \n",
       "std     378.020061    0.486592     0.837836    14.413493     1.041658   \n",
       "min       1.000000    0.000000     1.000000     0.170000     0.000000   \n",
       "25%     328.000000    0.000000     2.000000    21.000000     0.000000   \n",
       "50%     655.000000    0.000000     3.000000    28.000000     0.000000   \n",
       "75%     982.000000    1.000000     3.000000    39.000000     1.000000   \n",
       "max    1309.000000    1.000000     3.000000    80.000000     8.000000   \n",
       "\n",
       "             Parch         Fare  \n",
       "count  1309.000000  1308.000000  \n",
       "mean      0.385027    33.295479  \n",
       "std       0.865560    51.758668  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     7.895800  \n",
       "50%       0.000000    14.454200  \n",
       "75%       0.000000    31.275000  \n",
       "max       9.000000   512.329200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: colunas com valores não numéricos são excluídas dessa visualização (veja que a coluna Name não aparece, por exemplo).\n",
    "\n",
    "Vamos listar as *features* com valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin          0.774637\n",
       "Survived       0.319328\n",
       "Age            0.200917\n",
       "Embarked       0.001528\n",
       "Fare           0.000764\n",
       "Ticket         0.000000\n",
       "Parch          0.000000\n",
       "SibSp          0.000000\n",
       "Sex            0.000000\n",
       "Name           0.000000\n",
       "Pclass         0.000000\n",
       "PassengerId    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_raw.isnull().sum()/len(df_raw)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessas visualizações, podemos tirar algumas conclusões:\n",
    "\n",
    "- As colunas *Age*, *Cabin*, *Embarked* possuem valores nulos (*Survived* é a nossa variável dependente; esses valores nulos referem-se às entradas do dataset de teste);\n",
    "- A coluna *Sex*, *Ticket* e *Embarked* devem ser categorizadas - os algoritmos de Machine Learning precisam de entradas do tipo numérico; não sabem lidar com texto;\n",
    "- As colunas *Name*  e *PassengerId*, em princípio, não fazem sentido. Provavelmente nossa variável dependente, *Survived*, não se relaciona com elas. Logo, podemos removê-las."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando os nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria das bibliotecas de *Machine Learning*, incluindo a scikit-learn, disparam erros ao usar dados com valores nulos. Por isso precisamos tratar esses valores. Temos algumas alternativas:\n",
    "\n",
    "- remover as linhas com valores nulos (essa não costuma ser uma boa ideia, pois, estamos jogando fora linhas que possuem outras informações por causa de valores nulos em determinadas colunas);\n",
    "- remover as colunas que possuem valores nulos (sob pena de perda de informação, caso elas sejam úteis);\n",
    "- *Imputation*: preencher os valores nulos com algum valor; por exemplo, podemos substituir os nulos presentes em uma coluna pela média, mediana ou moda dos valores da coluna; esse procedimento nos dá um melhor resultado do que a simples remoção da coluna;\n",
    "\n",
    "Vamos usar as duas últimas alternativas acima. \n",
    "\n",
    "**Nota**: dado ao alto índice de valores nulos (77%), vamos optar por remover a coluna *Cabin*;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df_raw.copy()\n",
    "df_copy.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma boa prática, antes de fazer os tratamentos necessários nos dados, é criar uma cópia dos dados originais, de forma que estes fiquem intactos. Foi isso que fizemos ao criar a variável *df_copy*.\n",
    "\n",
    "O método *drop()* permite-nos remover colunas (quando axis=1; se axis=0, estamos removendo linhas). Via de regra, o método *drop()* retorna um novo DataFrame sem as colunas que foram removidas; quando usamos *inplace=True*, *drop()* remove as colunas do próprio DataFrame, sem a necessidade de retornar um outro DataFrame.\n",
    "\n",
    "Para as colunas *Age* e *Fare*, vamos colocar no lugar dos valores nulos a média das idades presentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_not_null = df_copy[df_copy['Age'].isnull() == False]['Age']\n",
    "fare_not_null = df_copy[df_copy['Fare'].isnull() == False]['Fare']\n",
    "mean_age = age_not_null.mean()\n",
    "mean_fare = fare_not_null.mean()\n",
    "df_copy.fillna(value = {'Age':mean_age, 'Fare' : mean_fare}, inplace=True) # substituímos os nulos pela média"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a coluna *Embarked*, do tipo categórica, podemos usar a moda.\n",
    "\n",
    "Vamos visualizar os dados presentes nessa coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f29e60d4278>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_copy['Embarked'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor mais comun, a moda, é o valor 'S'. Vamos substituir por este valor os valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.fillna(value={'Embarked': 'S'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver agora os valores nulos que temos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       0.319328\n",
       "Embarked       0.000000\n",
       "Fare           0.000000\n",
       "Ticket         0.000000\n",
       "Parch          0.000000\n",
       "SibSp          0.000000\n",
       "Age            0.000000\n",
       "Sex            0.000000\n",
       "Name           0.000000\n",
       "Pclass         0.000000\n",
       "PassengerId    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_copy.isnull().sum()/len(df_copy)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto. Tratamos todos os nulos. Podemos prosseguir com o pré-processamento de dados.\n",
    "\n",
    "**Nota**: lembre-se que a coluna *Survived*, que é a nossa variável alvo, tem valores nulos provenientes dos dados do arquivo de teste - é o que vamos prever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lidando com variáveis categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis categóricas são aquelas cujos valores são limitados a um conjunto de valores. Um exemplo de variável categórica em nosso conjunto de dados é *Embarked*, que representa o porto de embarque; os seus valores são 'S', 'C' e 'Q'.\n",
    "\n",
    "Assim como no caso dos valores nulos, passar variáveis categóricas para modelos de *Machine Learning* também resultam em erros. Por isso precisamos tratar esses valores.\n",
    "\n",
    "A forma mais popular de tratamento de variáveis categóricas é o **One-Hot Encoding**.\n",
    "\n",
    "**One-Hot Encoding** cria novas colunas, binárias, indicando a presença ou ausência de cada um dos valores categóricos no conjunto de dados original. É uma boa técnica quando o conjunto de valores categóricos não é muito grande - caso contrário, vamos ter uma explosão de colunas.\n",
    "\n",
    "Primeiramente, vamos visualizar os tipos de dados de cada uma das nossas *features* (colunas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived       float64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis do tipo **object** indicam que elas possuem texto. Essas, em geral, são colunas que devem passar pelo processo de *encoding*.\n",
    "\n",
    "Vamos verificar a quantidade de valores únicos em cada uma dessas colunas *object*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 1307, 'Sex': 2, 'Ticket': 929, 'Embarked': 3}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = {}\n",
    "for col in df_copy.columns:\n",
    "    if df_copy[col].dtype == 'object':\n",
    "        unique_values[col] = len(df_copy[col].unique())\n",
    "        \n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se fizemos *one-hot encoding* diretamente, as colunas *Name* e *Ticket* vão gerar diversas colunas binárias. Logo, não é uma boa ideia usar o encoding nelas.\n",
    "\n",
    "Primeiramente, vamos ignorar a coluna *Name*. Vamos fazer isso porque o hot-encoding dela geraria uma explosão de colunas; e, também, porque conforme dissemos anteriomente, acreditamos que ela não deve estar relacionada com a variável alvo, não devendo ter, portanto, importância para o modelo (o nome da pessoa não deve influenciar se ela sobrevive ou não).\n",
    "\n",
    "Depois, vamos categorizar as variáveis *Ticket* e *Sex*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.drop('Name', axis=1, inplace=True)\n",
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>913</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>768</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>627</td>\n",
       "      <td>78.2667</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>883</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>763</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>651</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>91.0792</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex        Age  SibSp  Parch  Ticket  \\\n",
       "359          360       1.0       3    0  29.881138      0      0     391   \n",
       "142          143       1.0       3    0  24.000000      1      0     913   \n",
       "250         1142       NaN       2    0   0.920000      1      2     768   \n",
       "591          592       1.0       1    0  52.000000      1      0     627   \n",
       "115         1007       NaN       3    1  18.000000      1      0     275   \n",
       "9             10       1.0       2    0  14.000000      1      0     174   \n",
       "159         1051       NaN       3    0  26.000000      0      2     883   \n",
       "145          146       0.0       2    1  19.000000      1      1     763   \n",
       "785          786       0.0       3    1  25.000000      0      0     651   \n",
       "484          485       1.0       1    1  25.000000      1      0      82   \n",
       "\n",
       "        Fare Embarked  \n",
       "359   7.8792        Q  \n",
       "142  15.8500        S  \n",
       "250  27.7500        S  \n",
       "591  78.2667        C  \n",
       "115  14.4542        C  \n",
       "9    30.0708        C  \n",
       "159  13.7750        S  \n",
       "145  36.7500        S  \n",
       "785   7.2500        S  \n",
       "484  91.0792        C  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformamos texto em categoria\n",
    "df_copy['Ticket'] = df_copy['Ticket'].astype('category')\n",
    "df_copy['Sex'] = df_copy['Sex'].astype('category')\n",
    "# Substitui os valores pelos códigos de cada categoria\n",
    "df_copy['Ticket'] = df_copy['Ticket'].cat.codes\n",
    "df_copy['Sex'] = df_copy['Sex'].cat.codes\n",
    "\n",
    "\n",
    "df_copy.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, as variáveis *Ticket* e *Sex* tiveram seus valores substituídos pelos códigos numéricos correspondentes.\n",
    "\n",
    "Agora, finalmente, vamos aplicar o one-hot encoding no DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>1279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>78.8500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>781</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>872</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>833</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>321</td>\n",
       "      <td>18.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch  Ticket      Fare  \\\n",
       "387         1279       NaN       2    1  57.0      0      0     195   13.0000   \n",
       "245         1137       NaN       1    1  41.0      1      0     110   51.8625   \n",
       "741          742       0.0       1    1  36.0      1      0     118   78.8500   \n",
       "349         1241       NaN       2    0  31.0      0      0     781   21.0000   \n",
       "189         1081       NaN       2    1  40.0      0      0     306   13.0000   \n",
       "415         1307       NaN       3    1  38.5      0      0     872    7.2500   \n",
       "380          381       1.0       1    0  42.0      0      0     833  227.5250   \n",
       "149          150       0.0       2    1  42.0      0      0     194   13.0000   \n",
       "595          596       0.0       3    1  36.0      1      1     425   24.1500   \n",
       "437          438       1.0       2    0  24.0      2      3     321   18.7500   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  \n",
       "387           0           0           1  \n",
       "245           0           0           1  \n",
       "741           0           0           1  \n",
       "349           0           0           1  \n",
       "189           0           0           1  \n",
       "415           0           0           1  \n",
       "380           1           0           0  \n",
       "149           0           0           1  \n",
       "595           0           0           1  \n",
       "437           0           0           1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = pd.get_dummies(df_copy)\n",
    "df_copy.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função *get_dummies* do pandas permite fazer *one-hot encoding*, convertendo variáveis categóricas em variáveis indicadores (*dummy*).\n",
    "\n",
    "Observe, da saída resultante de sample(), que foram criadas variáveis adicionais derivadas de *Embarked*:  \n",
    "\n",
    "- *Embarked_C*: indicando que o valor original era 'C';\n",
    "- *Embarked_Q*: indicando que o valor original era 'Q';\n",
    "- *Embarked_S*: indicando que o valor original era 'S';\n",
    "\n",
    "Em cada linha, somente uma dessas variáveis terá seu valor igual a 1, com as outras tendo o valor 0.\n",
    "\n",
    "Agora, com todas as variáveis tendo valores numéricos, podemos partir para o treino do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando um modelo\n",
    "\n",
    "Agora podemos treinar o modelo. Vamos, primeiramente, separar novamente os data sets de treino e teste, conforme os arquivos originalmente nos fornecidos pelo Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_copy[0:891] # o tamanho original do set de treino é 891\n",
    "df_test = df_copy[891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de agora, vamos utilizar o set de treino para fazer o treino do nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n"
     ]
    }
   ],
   "source": [
    "cols_to_remove = ['PassengerId', 'Survived']\n",
    "\n",
    "features = [c for c in df_train.columns if c not in cols_to_remove]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No trecho anterior removemos as variáveis *PassengerId* (pelo fato de acreditarmos que ela não se relaciona com a nossa variável alvo - é apenas um sequencial numérico) e a variável alvo *Survived*. O objetivo é selecionar as *features* que vamos utilizar para treinar nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# usando n_estimators = 100, para suprimir warning\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(df_train[features], df_train['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No trecho anterior, criamos um classificador do tipo RandomForest e em seguida chamamos o seu método *fit*, para fazer o treino do modelo - a construção das árvores, neste caso.\n",
    "\n",
    "O primeiro argumento de *fit* é a entrada para o treino (X); o segundo argumento é a variável alvo (y).\n",
    "\n",
    "Agora vamos fazer a previsão do resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(df_train[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função *predict()* nos retorna os valores que queremos prever, neste caso, o valor de *Survived*.\n",
    "\n",
    "Esse é o padrão para treino de modelos utilizando scikit-learn: chamar *fit* para fazer o ajuste e depois *predict* para fazer a previsão.\n",
    "\n",
    "Vamos ver a acurácia das nossas previsões no dataset de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988776655443322"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(df_train['Survived'], train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos como métrica a acurácia - essa é a métrica recomendada pelo Kaggle para esse problema. Fizemos uso do *accuracy_score* do scikit-learn; o seu primeiro argumento são os valores reais; o segundo argumento são os valores previstos.\n",
    "\n",
    "Nesse caso, o modelo está conseguindo acertar 99% das previsões.\n",
    "\n",
    "O que fizemos até agora nos garante que o nosso modelo tem um ótimo desempenho nos dados conhecidos,  o conjunto de treino - quase 100%. No entanto, precisamos garantir que o modelo também se comporte bem para dados que ele ainda não conhece; em outras palavras, queremos um modelo que generalize bem para novos dados que lhe sejam apresentados - evitar o **overfitting**.\n",
    "\n",
    "Para avaliar quão bom é o desempenho do modelo treinado em dados desconhecidos, vamos separar o *dataset* de treino em 2 outros *datasets* separados: treino e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split: Criando os conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 10), (179, 10), (712,), (179,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[features], df_train['Survived'], test_size = 0.2, random_state = 42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fizemos uso da função *train_test_split* do scikit-learn para separar, aleatoriamente, o dataset de treino df_train em outros dois datasets independentes: X_train e X_test.\n",
    "\n",
    "Agora, vamos treinar o modelo utilizando o X_train e avaliá-lo utilizando o X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9985955056179775, 0.8044692737430168)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_train, model.predict(X_train)), accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, o desempenho no set de treino é bem maior do que no set de teste: 99% vs 80% - embora precisão de 80% seja um resultado razoável. O que está ocorrendo aqui é o **overfitting**.\n",
    "\n",
    "O **overfitting** ocorre quando o modelo captura bem as características presentes no set de treinamento, mas falha ao generalizar seu comportamento para dados que ele desconhece - fazendo uma analogia, é como se ele decorasse as características existentes, em vez de aprendê-la.\n",
    "\n",
    "Há diversas formas de tratar o overfitting, como melhora de hiperparâmetros, melhor tratamento de dados, etc. Não vamos entrar nesse tópico, para não fugir do escopo desse caderno, que é a criação de um classificador simples e rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando se o classificador criado é bom\n",
    "\n",
    "Vimos que o classificador tem uma acurácia de 80% no dataset de teste. 80%, para a maioria dos problemas, parece ser um bom resultado. Mas quão bom é esse valor?\n",
    "\n",
    "Vamos comparar o nosso classificador com um classificador que *dummy*, isto é, um classificador que sempre prevê o mesmo valor (por exemplo, ele sempre \"chuta\" que o passageiro vai morrer). Esperamos que o nosso classificador seja melhor que esse, caso contrário, não faz sentido utilizá-lo.\n",
    "\n",
    "Vamos dar uma olhada nos nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f29d9b77240>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['Survived'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer um classificador que, independentemente dos dados, sempre chuta que o passageiro vai sobreviver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6235955056179775, 0.5865921787709497)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# cria um classificador que faz previsões baseados na classe mais frequente\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_train, dummy.predict(X_train)), accuracy_score(y_test, dummy.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme podemos ver, a acurácia do classificador que sempre prevê o mesmo valor, é de 58.6% no dataset de treino. Logo, o nosso classificador baseado em RandomForest está bem melhor que esse.\n",
    "\n",
    "Vamos fazer a análise final, que seria a submissão dos resultados para o Kaggle, baseado no arquivo com os dados de testes que nos foi fornecido (test.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado junto ao arquivo de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrethiago/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "output_predictions = model.predict(df_test[features])\n",
    "df_test['Survived'] = pd.Series(output_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "5            897         0\n",
       "6            898         0\n",
       "7            899         0\n",
       "8            900         1\n",
       "9            901         0\n",
       "10           902         0\n",
       "11           903         0\n",
       "12           904         1\n",
       "13           905         0\n",
       "14           906         1\n",
       "15           907         1\n",
       "16           908         0\n",
       "17           909         0\n",
       "18           910         0\n",
       "19           911         1\n",
       "20           912         0\n",
       "21           913         0\n",
       "22           914         1\n",
       "23           915         0\n",
       "24           916         1\n",
       "25           917         0\n",
       "26           918         1\n",
       "27           919         0\n",
       "28           920         0\n",
       "29           921         0\n",
       "..           ...       ...\n",
       "388         1280         0\n",
       "389         1281         0\n",
       "390         1282         1\n",
       "391         1283         1\n",
       "392         1284         0\n",
       "393         1285         0\n",
       "394         1286         0\n",
       "395         1287         1\n",
       "396         1288         0\n",
       "397         1289         1\n",
       "398         1290         0\n",
       "399         1291         0\n",
       "400         1292         1\n",
       "401         1293         0\n",
       "402         1294         1\n",
       "403         1295         0\n",
       "404         1296         0\n",
       "405         1297         0\n",
       "406         1298         0\n",
       "407         1299         0\n",
       "408         1300         1\n",
       "409         1301         1\n",
       "410         1302         1\n",
       "411         1303         1\n",
       "412         1304         0\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ouput = pd.DataFrame({ 'PassengerId': df_test['PassengerId'],\n",
    "                            'Survived': df_test['Survived'] }, dtype=int)\n",
    "display(df_ouput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
